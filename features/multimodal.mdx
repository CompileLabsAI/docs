---
title: "Multimodal"
description: "Process text, images, and other media types together"
icon: "layer-group"
---

## Overview

Compile Labs provides access to AI models across multiple modalities - text understanding and generation, image analysis, and image creation - all through a single unified API. This means you can build rich, multi-sensory applications without managing different APIs for each modality.

## Available Modalities

### Text-to-Text Models

Process and generate natural language for conversations, content creation, code generation, and reasoning tasks. These models power chat interfaces, content assistants, translation services, and sophisticated reasoning workflows.

**What you can do:**
- Conversational AI and chatbots
- Long-form content generation
- Code generation and analysis
- Multi-step reasoning and planning
- Translation and summarization

### Text-and-Image-to-Text Models

Analyze images alongside text prompts to understand visual content, answer questions about images, extract information from documents, and reason about what's shown in pictures.

**What you can do:**
- Visual question answering
- Document and chart analysis
- Image captioning and description
- Content moderation with visual context
- Product image analysis for e-commerce

### Text-to-Image Models

Generate images from text descriptions, enabling creative workflows, rapid prototyping, and visual content creation at scale.

**What you can do:**
- Marketing asset generation
- Concept visualization and prototyping
- Product mockups and design exploration
- Illustration and creative content
- Custom image generation for applications

## Benefits of a Unified Interface

### One API for All Modalities

Access text, vision, and image generation models through the same authentication, request format, and SDKs. No need to integrate multiple vendor APIs or manage different authentication schemes.

### Consistent Developer Experience

Whether you're generating text, analyzing images, or creating visuals, you use the same request patterns, error handling, and monitoring tools. This dramatically reduces integration complexity.

### Simplified Billing and Usage Tracking

All usage across modalities appears in a single dashboard with unified billing. Track costs, set quotas, and monitor usage for text and image models in one place.

### Flexible Model Selection

Switch between models or experiment with different providers without changing your integration. Try Llama for text, Claude for vision, and FLUX for images - all through one API.

### Future-Proof Architecture

As new models emerge across modalities (text, image, audio, video, 3D), they'll integrate seamlessly into the same unified interface. 

## Next Steps

<CardGroup cols={2}>

<Card title="Chat Completions" icon="comments" href="/modalities/chat-completions-openai">
Build multimodal applications
</Card>

<Card title="Image Generation" icon="image" href="/modalities/image-generation">
Generate images with AI
</Card>

</CardGroup>

