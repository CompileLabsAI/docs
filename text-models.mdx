---
title: "Text Models"
description: "Browse all available text and language models"
icon: "comments"
---

## Overview

Text models support chat completions, language understanding, and text generation tasks. All models are accessible through our unified API.

## Anthropic

**Inputs**: Text  
**Use Cases**: General-purpose language tasks, content generation, conversation

**Claude Sonnet 4**
 - Model ID: `anthropic/claude-sonnet-4`
 - Overview: Balanced, high-accuracy reasoning and coding; great for complex agents and long-form generation.
- Context Length: 128K tokens
- Pricing: Input \$3 per 1M tokens; Output \$15 per 1M tokens
- Status: Active

**Claude Sonnet 4.5**
 - Model ID: `anthropic/claude-sonnet-4.5`
 - Overview: Latest Claude for top-tier reasoning and code; excels at tool use and instruction following.
- Context Length: 128K tokens
- Pricing: Input \$3 per 1M tokens; Output \$15 per 1M tokens
- Status: Active

**Claude Haiku 4.5**
 - Model ID: `anthropic/claude-haiku-4.5`
 - Overview: Fast, budget-friendly Claude; ideal for high-throughput chat, classification, and lightweight RAG.
- Context Length: 128K tokens
- Pricing: Input \$0.40 per 1M tokens; Output \$1.60 per 1M tokens
- Status: Active

## Google

**Inputs**: Text  
**Use Cases**: General-purpose language tasks, content generation, conversation

**Gemini 2.5 Pro**
 - Model ID: `google/gemini-2.5-pro`
 - Overview: Strong analytical and coding capabilities with long context; great for complex reasoning and math.
- Context Length: 128K tokens
- Pricing: Input \$1.25 per 1M tokens; Output \$10 per 1M tokens
- Status: Active

**Gemini 2.5 Flash**
 - Model ID: `google/gemini-2.5-flash`
 - Overview: Low-latency, cost-efficient Gemini; ideal for assistants, drafts, and autocomplete.
- Context Length: 128K tokens
- Pricing: Input \$0.30 per 1M tokens; Output \$2.50 per 1M tokens
- Status: Active

**Gemini 2.5 Flash Lite**
 - Model ID: `google/gemini-2.5-flash-lite`
 - Overview: Ultra-low-cost variant for simple tasks at massive scale.
- Context Length: 128K tokens
- Pricing: Input \$0.30 per 1M tokens; Output \$2.50 per 1M tokens
- Status: Active

**Gemini 2.0 Flash**
 - Model ID: `google/gemini-2.0-flash`
 - Overview: Fast general-purpose text model; good for summarization and interactive assistants.
- Context Length: 128K tokens
- Pricing: Input \$0.30 per 1M tokens; Output \$2.50 per 1M tokens
- Status: Active

## OpenAI

**Inputs**: Text  
**Use Cases**: General-purpose language tasks, content generation, conversation

**GPT-5**
 - Model ID: `openai/gpt-5`
 - Overview: General-purpose frontier model; best for complex reasoning, coding, and agent workflows.
- Context Length: 128K tokens
- Pricing: Input \$3 per 1M tokens; Output \$15 per 1M tokens
- Status: Active

**GPT-5 Mini**
 - Model ID: `openai/gpt-5-mini`
 - Overview: Lightweight, low-latency GPT; great for fast chat, routing, and control flows.
- Context Length: 128K tokens
- Pricing: Input \$0.40 per 1M tokens; Output \$1.60 per 1M tokens
- Status: Active

**GPT-4.1 Mini**
 - Model ID: `openai/gpt-4.1-mini`
 - Overview: Balanced quality and cost; strong at instruction following and structured outputs.
- Context Length: 128K tokens
- Pricing: Input \$0.40 per 1M tokens; Output \$1.60 per 1M tokens
- Status: Active

**GPT-4o Mini**
 - Model ID: `openai/gpt-4o-mini`
 - Overview: Optimized for low latency; ideal for interactive assistants and streaming responses.
- Context Length: 128K tokens
- Pricing: Input \$0.40 per 1M tokens; Output \$1.60 per 1M tokens
- Status: Active

**GPT-OSS 120B**
 - Model ID: `openai/gpt-oss-120b`
 - Overview: Large-capacity model for research and batch generation; good for long-form text.
- Context Length: 128K tokens
- Pricing: Input \$0.08 per 1M tokens; Output \$0.30 per 1M tokens
- Status: Active

## Meta

**Inputs**: Text  
**Use Cases**: General-purpose language tasks, content generation, conversation

**Llama 4 Scout**
 - Model ID: `moonshotai/kimi-k2-0905`
 - Overview: Open and efficient; strong for coding, multilingual tasks, and retrieval-augmented workflows.
- Context Length: 128K tokens
- Pricing: Input $0.08 per 1M tokens; Output $0.30 per 1M tokens
- Status: Active

## Qwen

**Inputs**: Text  
**Use Cases**: General-purpose language tasks, content generation, conversation

**Qwen3 235B**
 - Model ID: `qwen/qwen3-235b-a22b-2507`
 - Overview: Multilingual, long-context (262K) model; excels at math, coding, and tool use.
- Context Length: 262K tokens
- Pricing: Input \$0.08 per 1M tokens; Output \$0.55 per 1M tokens
- Status: Active

## Moonshot AI

**Inputs**: Text  
**Use Cases**: General-purpose language tasks, content generation, conversation

**Kimi K2**
 - Model ID: `moonshotai/kimi-k2-0905`
 - Overview: Agentic model optimized for planning and tool use; strong long-context summarization.
- Context Length: 128K tokens
- Pricing: Input \$0.39 per 1M tokens; Output \$1.90 per 1M tokens
- Status: Active

## DeepSeek

**Inputs**: Text  
**Use Cases**: General-purpose language tasks, content generation, conversation

**DeepSeek V3.1**
 - Model ID: `deepseek/deepseek-v3.1`
 - Overview: Reasoning-focused model; great for quantitative analysis, coding, and stepwise problem solving.
- Context Length: 128K tokens
- Pricing: Input \$0.20 per 1M tokens; Output \$1.50 per 1M tokens
- Status: Active

**DeepSeek V3**
 - Model ID: `deepseek/deepseek-v3-0324`
 - Overview: General-purpose DeepSeek; strong in code generation and math with fast responses.
- Context Length: 128K tokens
- Pricing: Input \$0.20 per 1M tokens; Output \$1.50 per 1M tokens
- Status: Active

**DeepSeek R1T2 Chimera**
 - Model ID: `deepseek/deepseek-r1t2-chimera`
 - Overview: Reasoning + tool-use hybrid; ideal for agent loops, planning, and complex tasks.
- Context Length: 128K tokens
- Pricing: Input \$0.20 per 1M tokens; Output \$1.50 per 1M tokens
- Status: Active

## xAI

**Inputs**: Text  
**Use Cases**: General-purpose language tasks, content generation, conversation

**Grok Code Fast 1**
 - Model ID: `x-ai/grok-code-fast-1`
 - Overview: Fast, economical code generation and editing; excels in agentic coding workflows.
- Context Length: 128K tokens
- Pricing: Input \$0.20 per 1M tokens; Output \$1.50 per 1M tokens
- Status: Active

**Grok 4 Fast**
 - Model ID: `x-ai/grok-4-fast`
 - Overview: High-speed general reasoning; good for chat, analysis, and routing.
- Context Length: 128K tokens
- Pricing: Input \$0.20 per 1M tokens; Output \$1.50 per 1M tokens
- Status: Active

## z-ai (GLM)

**Inputs**: Text  
**Use Cases**: General-purpose language tasks, content generation, conversation

**GLM-4.6**
 - Model ID: `z-ai/glm-4.6`
 - Overview: Multilingual general-purpose model; strong for Chinese-English tasks and Q&A.
- Context Length: 128K tokens
- Pricing: Input \$0.08 per 1M tokens; Output \$0.30 per 1M tokens
- Status: Active

## Listing Text Models

Get a complete list of all available text models via API:

```bash
curl "https://api.compilelabs.ai/v1/models?type=text_to_text" \
  -H "Authorization: Bearer YOUR_API_KEY"
```

## Model Status

- **Active**: Currently available for use
- **Pending**: Under review / not yet available

## Next Steps

<CardGroup cols={2}>

<Card title="Chat Completions (OpenAI)" icon="comments" href="/modalities/chat-completions-openai">
Start using text models with OpenAI SDK
</Card>

<Card title="Chat Completions (Anthropic)" icon="comments" href="/modalities/chat-completions-anthropic">
Start using text models with Anthropic SDK
</Card>

<Card title="Image Models" icon="image" href="/image-models">
Browse image generation models
</Card>

<Card title="Providers" icon="layer-group" href="/providers">
Learn about our AI providers
</Card>

</CardGroup>

